{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b19ac75d-b8ad-4e0e-9068-aecd973bde65",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pip install evidently==0.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67b9836c-1964-41e9-82ca-80597ec79c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pydantic==1.10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe22d37-3c38-49a7-a273-f07f9adf8f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from evidently.report import Report\n",
    "from evidently.metric_preset import DataDriftPreset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import mlflow\n",
    "from evidently.test_suite import TestSuite\n",
    "from evidently.test_preset import DataDriftTestPreset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e36d5d2-fb50-4805-a39a-2c88c25ddc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load clean dataset\n",
    "df = pd.read_csv('data/Telco-Customer-Churn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69c966cf-f42c-49be-b565-aaef56f86330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert TotalCharges and drop missing\n",
    "df[\"TotalCharges\"] = pd.to_numeric(df[\"TotalCharges\"], errors=\"coerce\")\n",
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc4fced-d564-4b98-8aa4-e5717321c739",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate drift: skew contract types, monthly charges, and tenure\n",
    "df_drifted = df.copy()\n",
    "\n",
    "df_drifted[\"Contract\"] = df_drifted[\"Contract\"].apply(\n",
    "    lambda x: \"Month-to-month\" if np.random.rand() < 0.7 else x\n",
    ")\n",
    "\n",
    "df_drifted[\"tenure\"] = df_drifted[\"tenure\"].apply(\n",
    "    lambda x: np.random.randint(0, 12) if np.random.rand() < 0.5 else x\n",
    ")\n",
    "\n",
    "df_drifted[\"MonthlyCharges\"] += np.random.normal(5, 10, size=len(df_drifted))\n",
    "\n",
    "# Save drifted version (optional)\n",
    "df_drifted.to_csv(\"data/processed_telco.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56094add-32cf-4cca-80c7-970f3c042fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = df.copy()\n",
    "cur = df_drifted.copy()\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in ref.select_dtypes(include=\"object\").columns:\n",
    "    ref[col] = le.fit_transform(ref[col])\n",
    "    cur[col] = le.transform(cur[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1abe3eb-dd1a-4525-88f7-feac6292dd48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drift report saved as 'drift_report.html'\n"
     ]
    }
   ],
   "source": [
    "report = Report(metrics=[DataDriftPreset()])\n",
    "report.run(reference_data=ref, current_data=cur)\n",
    "report.save_html(\"drift_report.html\")\n",
    "print(\"Drift report saved as 'drift_report.html'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08480968-fdf1-4376-a0f8-303612f9be57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged drift_score=0.143 (3/21) and report to MLflow\n",
      "Drift is within acceptable range.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Churn_Prediction_AdaptiveML\")\n",
    "\n",
    "# Extract drift metrics from your JSON result\n",
    "feature_stats = result[\"tests\"][0][\"parameters\"][\"features\"]\n",
    "n_total = len(feature_stats)\n",
    "n_drifted = sum(1 for _, f in feature_stats.items() if f[\"detected\"])\n",
    "drift_score = n_drifted / n_total\n",
    "\n",
    "# Log drift score + artifact to MLflow\n",
    "with mlflow.start_run(run_name=\"drift_monitoring_report\"):\n",
    "    mlflow.log_metric(\"drift_score\", drift_score)\n",
    "    mlflow.log_metric(\"drifted_columns\", n_drifted)\n",
    "    mlflow.log_metric(\"total_columns\", n_total)\n",
    "    mlflow.log_artifact(\"drift_report.html\")\n",
    "    print(f\"Logged drift_score={drift_score:.3f} ({n_drifted}/{n_total}) and report to MLflow\")\n",
    "\n",
    "    # Optional: trigger retrain\n",
    "    if drift_score > 0.3:\n",
    "        print(\"Drift is significant. Triggering retraining...\")\n",
    "        import subprocess\n",
    "        subprocess.call([\"python\", \"retrain_on_drift.py\"])\n",
    "    else:\n",
    "        print(\"Drift is within acceptable range.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1025b75-9ba2-4eaa-827c-3bd327ebbdab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
